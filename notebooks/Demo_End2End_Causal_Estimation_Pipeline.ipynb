{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VectorInstitute/Causal_Inference_Laboratory/blob/main/notebooks/Demo_End2End_Causal_Estimation_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation\n",
        "\n",
        "## Upload Code\n",
        "\n",
        "Run this code to clone the repository and prepare it. \n"
      ],
      "metadata": {
        "id": "WWXJoMBul0VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VectorInstitute/Causal_Inference_Laboratory.git\n",
        "!mv Causal_Inference_Laboratory code\n",
        "!mv code/data ./data\n",
        "!mv code/utils ./utils\n",
        "!mv code/models ./models\n",
        "!mv code/estimation_results ./estimation_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND9rTitGpFpp",
        "outputId": "52f3f3b0-c106-40c3-e7ad-bddee28eac08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Causal_Inference_Laboratory'...\n",
            "remote: Enumerating objects: 497, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 497 (delta 96), reused 88 (delta 42), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (497/497), 27.99 MiB | 17.97 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n",
            "mv: cannot stat 'code/data': No such file or directory\n",
            "mv: cannot stat 'code/utils': No such file or directory\n",
            "mv: cannot stat 'code/models': No such file or directory\n",
            "mv: cannot stat 'code/estimation_results': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost==1.3.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtP3r5ybskjO",
        "outputId": "c109f0d5-1e8a-4477-e7f9-099d92d4b010"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost==1.3.3 in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost==1.3.3) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost==1.3.3) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYyfPzSok-1d"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zKhGq-ljk-1g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import utils.estimators as models\n",
        "import utils.preprocessing as helper\n",
        "from utils.preprocessing import sys_config\n",
        "import utils.metrics as metrics\n",
        "from utils.evaluation import *\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ACFe3LMek-1i"
      },
      "outputs": [],
      "source": [
        "datasets_folder = sys_config[\"datasets_folder\"]\n",
        "results_folder = sys_config[\"results_folder\"]\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNPhsTZVk-1i"
      },
      "source": [
        "# Description of datasets\n",
        "We briefly discuss the datasets here.\n",
        "\n",
        "## Jobs\n",
        "Jobs is a dataset derived from LaLonde [2] where the original data set has job\n",
        "training as the treatment and income and employment status after training as\n",
        "outcomes. The Jobs dataset is proposed in [3] using the LaLonde experimental\n",
        "sample (297 treated, 425 control) and the PSID comparison group (2490 control).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The Jobs datasets are already split into the train (2570 for each realization)\n",
        "and test (642 for each realization) splits in a 80/20 split. Each `.npz` file\n",
        "contains the following keys: x, t, yf, ate, which are respectively\n",
        "covariates, treatment, factual outcome, and average treatment effect (scalar).\n",
        "- Jobs: 10 realizations of the Jobs dataset (included in our repo);\n",
        "\n",
        "## Twins\n",
        "\n",
        "TWINS [4]. The dataset is from the data of twin births in the USA between 1989-1991 [5] about the effect of the relative weight of each of the twins on the morality of them. The treatment is whether the twin is born heavier than the other twin (T = 1 means heavier) and the outcomes are the first-year mortality of the twins. It has 23968 units (11984 treated, 11984 control) and 46 covariates relating to the parents, the pregnancy and birth.\n",
        "\n",
        "## IHDP\n",
        "Infant Health and Development Program (IHDP) [1] is from a\n",
        "randomized experiment studying the effect of home visits by specialists on\n",
        "future cognitive test scores of children. The children of non-white mothers in\n",
        "the treated set are removed to de-randomize the experiment. Each unit is\n",
        "simulated for a treated and a control outcome (so we know the ground-truth of\n",
        "the individual treatment effects).\n",
        "\n",
        "The IHDP datasets are already split into the train (672 for each realization)\n",
        "and test (75 for each realization) splits in a 90/10 split. Each `.npz` file\n",
        "contains the following keys: x, t, yf, ycf, mu0, mu1, which are respectively\n",
        "covariates, treatment, factual outcome, counterfactual outcome, noiseless\n",
        "potential control outcome, and noiseless potential treated outcome.\n",
        "- IHDP-100: 100 realizations of the IHDP dataset (included in our repo);\n",
        "- IHDP-1000: 1000 realizations of the IHDP dataset\n",
        "(downloadable from https://www.fredjo.com/);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j-pxJ4fHk-1j"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"TWINS\" #@param [\"Jobs\", \"TWINS\", \"IHDP-100\"]\n",
        "if dataset_name == \"Jobs\":\n",
        "  x_all, t_all, yf_all = helper.load_Jobs_observational(\n",
        "      datasets_folder, dataset_name, details=False\n",
        "  )\n",
        "  x_test_all, t_test_all, yf_test_all = helper.load_Jobs_out_of_sample(\n",
        "      datasets_folder, dataset_name, details=False\n",
        "  )\n",
        "elif dataset_name == \"TWINS\":\n",
        "  x_all, t_all, yf_all = helper.load_TWINS_observational(\n",
        "      datasets_folder, dataset_name, details=False\n",
        "  )\n",
        "  x_test_all, t_test_all, yf_test_all = helper.load_TWINS_out_of_sample(\n",
        "      datasets_folder, dataset_name, details=False\n",
        "  )\n",
        "elif dataset_name == \"IHDP-100\":\n",
        "  x_all, t_all, yf_all = helper.load_IHDP_observational(\n",
        "      datasets_folder, dataset_name, details=False\n",
        "  )\n",
        "  x_test_all, t_test_all, yf_test_all = helper.load_IHDP_out_of_sample(\n",
        "      datasets_folder, dataset_name, details=False\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1_a0EeWk-1l"
      },
      "source": [
        "## Estimation\n",
        "\n",
        "The estimators available are:\n",
        "- COM/S-Learner: OLS1, RF1, NN1;\n",
        "- GCOM/T-Learner: OLS2, RF2, NN2;\n",
        "- TARNet\n",
        "- Dragonnet\n",
        "\n",
        "Run and save estimatotion results using a specified estimator. Pre-trained estimation results are already provided, so to save time, you can skip the 2 cells below and proceed to Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t-zbX9PZk-1l"
      },
      "outputs": [],
      "source": [
        "def estimate(estimator_name):\n",
        "    num_realizations = x_all.shape[-1]\n",
        "    print(\"Numer of realizations:\", num_realizations)\n",
        "    y0_in_all, y1_in_all, y0_out_all, y1_out_all = [], [], [], []\n",
        "    ate_in_all, ate_out_all = [], []\n",
        "    for i in range(num_realizations):\n",
        "        text = f\" Estimation of realization {i} via {estimator_name}\"\n",
        "        print(f\"{text:-^79}\")\n",
        "        x, t, yf = x_all[:, :, i], t_all[:, i], yf_all[:, i]\n",
        "        x_test = x_test_all[:, :, i]\n",
        "        # train the estimator and predict for this realization\n",
        "        (\n",
        "            y0_in,\n",
        "            y1_in,\n",
        "            ate_in,\n",
        "            y0_out,\n",
        "            y1_out,\n",
        "            ate_out,\n",
        "        ) = models.train_and_evaluate(x, t, yf, x_test, estimator_name, dataset_name)\n",
        "        y0_in_all.append(y0_in)\n",
        "        y1_in_all.append(y1_in)\n",
        "        ate_in_all.append(ate_in)\n",
        "        y0_out_all.append(y0_out)\n",
        "        y1_out_all.append(y1_out)\n",
        "        ate_out_all.append(ate_out)\n",
        "    # follow the dimension order of the dataset,\n",
        "    # i.e., realizations are captured by the last index\n",
        "    y0_in_all = np.squeeze(np.array(y0_in_all).transpose()).reshape((-1, num_realizations))\n",
        "    y1_in_all = np.squeeze(np.array(y1_in_all).transpose()).reshape((-1, num_realizations))\n",
        "    y0_out_all = np.squeeze(np.array(y0_out_all).transpose()).reshape((-1, num_realizations))\n",
        "    y1_out_all = np.squeeze(np.array(y1_out_all).transpose()).reshape((-1, num_realizations))\n",
        "    ate_in_all = np.array(ate_in_all).reshape((num_realizations,))\n",
        "    ate_out_all = np.array(ate_out_all).reshape((num_realizations,))\n",
        "\n",
        "    # save estimation results\n",
        "    estimation_result_folder = os.path.join(\n",
        "        results_folder, dataset_name, estimator_name\n",
        "    )\n",
        "    print(f\"Saving {estimation_result_folder}.\")\n",
        "    helper.save_in_and_out_results(\n",
        "        estimation_result_folder,\n",
        "        y0_in_all,\n",
        "        y1_in_all,\n",
        "        ate_in_all,\n",
        "        y0_out_all,\n",
        "        y1_out_all,\n",
        "        ate_out_all,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = \"OLS1\" #@param estimator_set = [\"OLS1\", \"OLS2\", \"NN1\", \"NN2\", \"RF1\", \"RF2\", \"Dragonnet\", \"TARNet\"]"
      ],
      "metadata": {
        "id": "B5YUTY8kNimq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate(estimator)"
      ],
      "metadata": {
        "id": "utH9AdZeWyx6",
        "outputId": "3e680463-01ae-42a3-c7a9-d0a815aa9e48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numer of realizations: 1\n",
            "--------------------- Estimation of realization 0 via OLS1---------------------\n",
            "Saving ./estimation_results/TWINS/OLS1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmAydp3Vk-1o"
      },
      "source": [
        "## Evalutation\n",
        " [6]\n",
        "![image](https://github.com/VectorInstitute/Causal_Inference_Laboratory/assets/47928320/e709567f-f280-4ac6-9572-5edeeef848e4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jaTQoY0Ik-1o"
      },
      "outputs": [],
      "source": [
        "def print_table(header, data):\n",
        "    table_width = 79\n",
        "    header_line = f'| {header.center(table_width - 4)} |'\n",
        "    separator_line = f'+{\"-\" * (table_width - 2)}+'\n",
        "\n",
        "    print(separator_line)\n",
        "    print(header_line)\n",
        "    print(separator_line)\n",
        "\n",
        "    for row in data:\n",
        "        row_line = f'| {row[0].ljust(30)} | {row[1].ljust(15)} | {str(row[2]).ljust(24)} |'\n",
        "        print(row_line)\n",
        "\n",
        "    print(separator_line)\n",
        "\n",
        "def evaluate(estimator_name, metrics_set, print_out=True):\n",
        "    if print_out:\n",
        "      print(f'{\" Evaluation \":-^79}')\n",
        "    results_in = {}\n",
        "    results_out = {}\n",
        "    if dataset_name == \"Jobs\":\n",
        "        x_all, t_all, yf_all = helper.load_Jobs_observational(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        x_test_all, t_test_all, yf_test_all = helper.load_Jobs_out_of_sample(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        ate_in_gt, ate_out_gt = helper.load_Jobs_ground_truth(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        mu0_in, mu1_in, mu0_out, mu1_out = None, None, None, None\n",
        "    elif dataset_name == \"TWINS\":\n",
        "        x_all, t_all, yf_all = helper.load_TWINS_observational(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        x_test_all, t_test_all, yf_test_all = helper.load_TWINS_out_of_sample(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        mu0_in, mu1_in, mu0_out, mu1_out = helper.load_TWINS_ground_truth(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        ate_in_gt = np.mean(mu1_in - mu0_in)\n",
        "        ate_out_gt = np.mean(mu1_out - mu0_out)\n",
        "    elif dataset_name == \"IHDP-100\":\n",
        "        x_all, t_all, yf_all = helper.load_IHDP_observational(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        x_test_all, t_test_all, yf_test_all = helper.load_IHDP_out_of_sample(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        mu0_in, mu1_in, mu0_out, mu1_out = helper.load_IHDP_ground_truth(\n",
        "            datasets_folder, dataset_name, details=False\n",
        "        )\n",
        "        ate_in_gt = np.mean(mu1_in - mu0_in)\n",
        "        ate_out_gt = np.mean(mu1_out - mu0_out)\n",
        "\n",
        "\n",
        "    # process in sample data\n",
        "    data_size_in = x_all.shape[0]\n",
        "    num_realizations_in = 1\n",
        "    if len(x_all.shape) == 3:\n",
        "        num_realizations_in = x_all.shape[2]\n",
        "        new_x_all = np.zeros((data_size_in * num_realizations_in, x_all.shape[1]))\n",
        "        for i in range(num_realizations_in):\n",
        "            new_x_all[i * data_size_in : (i + 1) * data_size_in, :] = x_all[:, :, i]\n",
        "        x_all = new_x_all\n",
        "\n",
        "    \n",
        "    # squeeze all eval data\n",
        "    x_all = np.reshape(x_all, (data_size_in*num_realizations_in, x_all.shape[1]))\n",
        "    t_all = np.reshape(t_all, (data_size_in * num_realizations_in), order='F')\n",
        "    yf_all = np.reshape(yf_all, (data_size_in * num_realizations_in), order='F')\n",
        "\n",
        "    indices_all = np.arange(x_all.shape[0])\n",
        "\n",
        "    x_train, x_eval_orig, t_train, t_eval_orig, yf_train, yf_eval_orig, indices_train, indices_eval = train_test_split(\n",
        "        x_all, t_all, yf_all, indices_all, test_size=0.2, random_state=seed\n",
        "        )\n",
        "    \n",
        "    # process out of sample data\n",
        "    data_size_out = x_test_all.shape[0]\n",
        "    num_realizations_out = 1\n",
        "    if len(x_test_all.shape) == 3:\n",
        "        num_realizations_out = x_test_all.shape[2]\n",
        "        new_x_test_all = np.zeros((data_size_out * num_realizations_out, x_test_all.shape[1]))\n",
        "        for i in range(num_realizations_out):\n",
        "            new_x_test_all[i * data_size_out : (i + 1) * data_size_out, :] = x_test_all[:, :, i]\n",
        "        x_test_all = new_x_test_all\n",
        "    \n",
        "    # squeeze all test data\n",
        "    x_test_all = np.reshape(x_test_all, (data_size_out*num_realizations_out, x_test_all.shape[1]))\n",
        "    t_test_all = np.reshape(t_test_all, (data_size_out * num_realizations_out), order='F')\n",
        "    yf_test_all = np.reshape(yf_test_all, (data_size_out * num_realizations_out), order='F')\n",
        "\n",
        "    #Computing relevant evaluation metric for ensemble for in sample data\n",
        "    nuisance_stats_dir= results_folder + '//..//models//' + dataset_name + '//'\n",
        "    # Nuisance Models\n",
        "    prop_prob_orig, prop_score_orig = get_nuisance_propensity_pred(x_eval_orig, t_eval_orig, save_dir=nuisance_stats_dir)\n",
        "    outcome_s_pred = get_nuisance_outome_s_pred(x_eval_orig, t_eval_orig, save_dir=nuisance_stats_dir)\n",
        "    outcome_t_pred = get_nuisance_outcome_t_pred(x_eval_orig, t_eval_orig, save_dir=nuisance_stats_dir)\n",
        "    outcome_r_pred = get_nuisance_outcome_r_pred(x_eval_orig, save_dir=nuisance_stats_dir)\n",
        "\n",
        "    outcome_s_pred_orig = np.array(outcome_s_pred)\n",
        "    outcome_t_pred_orig = np.array(outcome_t_pred)\n",
        "    outcome_r_pred_orig = np.array(outcome_r_pred)\n",
        "\n",
        "    #Computing relevant evaluation metric for ensemble for out of sample data\n",
        "    # Nuisance Models\n",
        "    prop_prob_test, prop_score_test = get_nuisance_propensity_pred(x_test_all, t_test_all, save_dir=nuisance_stats_dir)\n",
        "    outcome_s_pred = get_nuisance_outome_s_pred(x_test_all, t_test_all, save_dir=nuisance_stats_dir)\n",
        "    outcome_t_pred = get_nuisance_outcome_t_pred(x_test_all, t_test_all, save_dir=nuisance_stats_dir)\n",
        "    outcome_r_pred = get_nuisance_outcome_r_pred(x_test_all, save_dir=nuisance_stats_dir)\n",
        "\n",
        "    outcome_s_pred_test = np.array(outcome_s_pred)\n",
        "    outcome_t_pred_test = np.array(outcome_t_pred)\n",
        "    outcome_r_pred_test = np.array(outcome_r_pred)\n",
        "\n",
        "    estimation_result_folder = os.path.join(\n",
        "        results_folder, dataset_name, estimator_name\n",
        "    )\n",
        "    (\n",
        "        y0_in,\n",
        "        y1_in,\n",
        "        ate_in,\n",
        "        y0_out,\n",
        "        y1_out,\n",
        "        ate_out,\n",
        "    ) = helper.load_in_and_out_results(estimation_result_folder)\n",
        "    \n",
        "    if dataset_name == \"TWINS\":\n",
        "        y0_in = y0_in.reshape((-1, 1))\n",
        "        y1_in = y1_in.reshape((-1, 1))\n",
        "        y0_out = y0_out.reshape((-1, 1))\n",
        "        y1_out = y1_out.reshape((-1, 1))\n",
        "        ate_in = ate_in.reshape((-1, 1))\n",
        "        ate_out = ate_out.reshape((-1, 1))\n",
        "            \n",
        "    results_in[estimator_name] = {}\n",
        "    results_out[estimator_name] = {}\n",
        "\n",
        "    # process in sample data\n",
        "    ite_estimate_in = y1_in.reshape((-1, 1), order='F') - y0_in.reshape((-1, 1), order='F')\n",
        "    ite_estimate_eval = ite_estimate_in[indices_eval]\n",
        "\n",
        "    # get indices of non nan values\n",
        "    non_nan = ~np.isnan(ite_estimate_eval)\n",
        "    non_nan_inds = np.where(non_nan)[0]\n",
        "    ite_estimate_eval = ite_estimate_eval[non_nan_inds]\n",
        "    x_eval = np.take(x_eval_orig, non_nan_inds, axis=0)\n",
        "    t_eval = t_eval_orig[non_nan.squeeze()]\n",
        "    yf_eval = yf_eval_orig[non_nan.squeeze()]\n",
        "    \n",
        "    prop_score = prop_score_orig[non_nan.squeeze()]\n",
        "    outcome_s_pred = np.transpose(np.transpose(outcome_s_pred_orig)[non_nan.squeeze()])\n",
        "    outcome_t_pred = np.transpose(np.transpose(outcome_t_pred_orig)[non_nan.squeeze()])\n",
        "    outcome_r_pred = outcome_r_pred_orig[non_nan.squeeze()]\n",
        "    prop_prob = prop_prob_orig[non_nan.squeeze()]\n",
        "\n",
        "    # process out of sample data\n",
        "    ite_estimate_out = y1_out.reshape((-1, 1), order='F') - y0_out.reshape((-1, 1), order='F')\n",
        "    ite_estimate_eval_out = ite_estimate_out\n",
        "\n",
        "    # get indices of non nan values\n",
        "    non_nan = ~np.isnan(ite_estimate_eval_out)\n",
        "    non_nan_inds = np.where(non_nan)[0]\n",
        "    ite_estimate_eval_out = ite_estimate_eval_out[non_nan_inds]\n",
        "    x_eval_out = np.take(x_test_all, non_nan_inds, axis=0)\n",
        "    t_eval_out = t_test_all[non_nan.squeeze()]\n",
        "    yf_eval_out = yf_test_all[non_nan.squeeze()]\n",
        "\n",
        "    prop_score_out = prop_score_test[non_nan.squeeze()]\n",
        "    outcome_s_pred_out = np.transpose(np.transpose(outcome_s_pred_test)[non_nan.squeeze()])\n",
        "    outcome_t_pred_out = np.transpose(np.transpose(outcome_t_pred_test)[non_nan.squeeze()])\n",
        "    outcome_r_pred_out = outcome_r_pred_test[non_nan.squeeze()]\n",
        "    prop_prob_out = prop_prob_test[non_nan.squeeze()]\n",
        "\n",
        "    for metric in metrics_set:\n",
        "        metric_in = None\n",
        "        if metric in [\"MAE\", \"PEHE\"]:\n",
        "            metric_in = metrics.calculate_metrics(\n",
        "                y0_in, y1_in, ate_in, mu0_in, mu1_in, ate_in_gt, metric=metric\n",
        "            )\n",
        "            metric_out = metrics.calculate_metrics(\n",
        "                y0_out, y1_out, ate_out, mu0_out, mu1_out, ate_out_gt, metric=metric\n",
        "            )\n",
        "        elif metric == \"value_score\":\n",
        "            metric_in = metrics.calculate_value_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, dataset_name=dataset_name, prop_score=prop_score\n",
        "            )\n",
        "            metric_out = metrics.calculate_value_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, dataset_name=dataset_name, prop_score=prop_score_out\n",
        "            )\n",
        "        elif metric == \"value_dr_score\":\n",
        "            metric_in = metrics.calculate_value_dr_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred, dataset_name=dataset_name, prop_score=prop_score\n",
        "            )\n",
        "            metric_out = metrics.calculate_value_dr_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out, dataset_name=dataset_name, prop_score=prop_score_out\n",
        "            )\n",
        "        elif metric == \"value_dr_clip_prop_score\":\n",
        "            metric_in = metrics.calculate_value_dr_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred, dataset_name=dataset_name, prop_score=prop_score, min_propensity=0.1\n",
        "            )\n",
        "            metric_out = metrics.calculate_value_dr_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out, dataset_name=dataset_name, prop_score=prop_score_out, min_propensity=0.1\n",
        "            )\n",
        "        elif metric == \"tau_match_score\":\n",
        "            metric_in = metrics.calculate_tau_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out\n",
        "            )\n",
        "        elif metric == \"tau_iptw_score\":\n",
        "            metric_in = metrics.calculate_tau_iptw_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, prop_score=prop_score\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_iptw_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, prop_score=prop_score_out\n",
        "            )\n",
        "        elif metric == \"tau_iptw_clip_prop_score\":\n",
        "            metric_in = metrics.calculate_tau_iptw_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, prop_score=prop_score, min_propensity=0.1\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_iptw_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, prop_score=prop_score_out, min_propensity=0.1\n",
        "            )\n",
        "        elif metric == \"tau_dr_score\":\n",
        "            metric_in = metrics.calculate_tau_dr_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred, prop_score=prop_score\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_dr_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out, prop_score=prop_score_out\n",
        "            )\n",
        "        elif metric == \"tau_dr_clip_prop_score\":\n",
        "            metric_in = metrics.calculate_tau_dr_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred, prop_score=prop_score, min_propensity=0.1\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_dr_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out, prop_score=prop_score_out, min_propensity=0.1\n",
        "            )\n",
        "        elif metric == \"tau_s_score\":\n",
        "            metric_in = metrics.calculate_tau_s_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_s_pred\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_s_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_s_pred_out\n",
        "            )\n",
        "        elif metric == \"tau_t_score\":\n",
        "            metric_in = metrics.calculate_tau_t_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred\n",
        "            )\n",
        "            metric_out = metrics.calculate_tau_t_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out\n",
        "            )\n",
        "        elif metric == \"influence_score\":\n",
        "            metric_in = metrics.calculate_influence_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred, prop_prob=prop_prob\n",
        "            )\n",
        "            metric_out = metrics.calculate_influence_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out, prop_prob=prop_prob_out\n",
        "            )\n",
        "        elif metric == \"influence_clip_prop_score\":\n",
        "            metric_in = metrics.calculate_influence_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_t_pred, prop_prob=prop_prob, min_propensity=0.1\n",
        "            )\n",
        "            metric_out = metrics.calculate_influence_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_t_pred_out, prop_prob=prop_prob_out, min_propensity=0.1\n",
        "            )\n",
        "        elif metric == \"r_score\":\n",
        "            metric_in = metrics.calculate_r_risk(\n",
        "                ite_estimate_eval, x_eval, t_eval, yf_eval, outcome_pred=outcome_r_pred, treatment_prob=prop_prob[:, 1]\n",
        "            )\n",
        "            metric_out = metrics.calculate_r_risk(\n",
        "                ite_estimate_eval_out, x_eval_out, t_eval_out, yf_eval_out, outcome_pred=outcome_r_pred_out, treatment_prob=prop_prob_out[:, 1]\n",
        "            )\n",
        "\n",
        "        if metric_in is None:\n",
        "            results_in[estimator_name][metric] = {\"mean\": None}\n",
        "        else:\n",
        "            results_in[estimator_name][metric] = {\n",
        "                \"mean\": np.mean(metric_in, where=(metric_in != 0)),\n",
        "            }\n",
        "        if metric_out is None:\n",
        "            results_out[estimator_name][metric] = {\"mean\": None}\n",
        "        else:\n",
        "            results_out[estimator_name][metric] = {\n",
        "                \"mean\": np.mean(metric_out, where=(metric_out != 0)),\n",
        "            }\n",
        "    \n",
        "    if print_out:\n",
        "      # In-sample results\n",
        "      header_in = f' In-sample results '\n",
        "      data_in = [[metric, estimator_name, results_in[estimator_name][metric][\"mean\"]] for metric in metrics_set]\n",
        "\n",
        "      # Out-of-sample results\n",
        "      header_out = f' Out-of-sample results '\n",
        "      data_out = [[metric, estimator_name, results_out[estimator_name][metric][\"mean\"]] for metric in metrics_set]\n",
        "\n",
        "      print_table(header_in, data_in)\n",
        "      print_table(header_out, data_out)\n",
        "\n",
        "    return results_in, results_out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select which estimator you want to evaluate below."
      ],
      "metadata": {
        "id": "2Uzy4JDpM0AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = \"RF1\" #@param estimator_set = [\"OLS1\", \"OLS2\", \"NN1\", \"NN2\", \"RF1\", \"RF2\", \"Dragonnet\", \"TARNet\"]"
      ],
      "metadata": {
        "id": "FK41I9biBEa0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the metric (or \"ALL\") from below to retreive the value. Ensure you've selected an estimator at the previous step."
      ],
      "metadata": {
        "id": "sCArxGr7WoT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = \"ALL\" #@param [ \"MAE\", \"PEHE\", \"value_score\", \"value_dr_score\", \"value_dr_clip_prop_score\", \"tau_t_score\", \"tau_s_score\", \"tau_match_score\", \"tau_iptw_score\", \"tau_iptw_clip_prop_score\", \"tau_dr_score\", \"tau_dr_clip_prop_score\", \"influence_score\", \"influence_clip_prop_score\", \"r_score\", \"ALL\"]\n",
        "if metric == \"ALL\":\n",
        "  metric_set = [ \"MAE\", \"PEHE\", \"value_score\", \"value_dr_score\", \"value_dr_clip_prop_score\", \"tau_t_score\", \"tau_s_score\", \"tau_match_score\", \"tau_iptw_score\", \"tau_iptw_clip_prop_score\", \"tau_dr_score\", \"tau_dr_clip_prop_score\", \"influence_score\", \"influence_clip_prop_score\", \"r_score\"]\n",
        "else:\n",
        "  metric_set = [metric]\n",
        "\n",
        "evaluate(estimator, metric_set)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkyNYLSwdVeW",
        "outputId": "a30cc9e4-3940-4ab5-b4bb-ba27f7ee1d16"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------- Evaluation ----------------------------------\n",
            "+-----------------------------------------------------------------------------+\n",
            "|                              In-sample results                              |\n",
            "+-----------------------------------------------------------------------------+\n",
            "| MAE                            | RF1             | 0.05089809116511944      |\n",
            "| PEHE                           | RF1             | 0.30797084523466006      |\n",
            "| value_score                    | RF1             | 0.009195894664544062     |\n",
            "| value_dr_score                 | RF1             | -0.2969726344595105      |\n",
            "| value_dr_clip_prop_score       | RF1             | -0.2969726344595105      |\n",
            "| tau_t_score                    | RF1             | 0.027134706751234645     |\n",
            "| tau_s_score                    | RF1             | 0.025611134591419647     |\n",
            "| tau_match_score                | RF1             | 0.2374155370177268       |\n",
            "| tau_iptw_score                 | RF1             | 1.0134805043195076       |\n",
            "| tau_iptw_clip_prop_score       | RF1             | 1.0134805043195076       |\n",
            "| tau_dr_score                   | RF1             | 0.6308312392460579       |\n",
            "| tau_dr_clip_prop_score         | RF1             | 0.6308312392460579       |\n",
            "| influence_score                | RF1             | -0.054843222668647676    |\n",
            "| influence_clip_prop_score      | RF1             | -0.054843222668647676    |\n",
            "| r_score                        | RF1             | 0.09204565171921457      |\n",
            "+-----------------------------------------------------------------------------+\n",
            "+-----------------------------------------------------------------------------+\n",
            "|                            Out-of-sample results                            |\n",
            "+-----------------------------------------------------------------------------+\n",
            "| MAE                            | RF1             | 0.046357947434292876     |\n",
            "| PEHE                           | RF1             | 0.325383506598431        |\n",
            "| value_score                    | RF1             | 0.18885336374994752      |\n",
            "| value_dr_score                 | RF1             | -0.04820085369682172     |\n",
            "| value_dr_clip_prop_score       | RF1             | -0.04820085369682172     |\n",
            "| tau_t_score                    | RF1             | 0.00873143477546668      |\n",
            "| tau_s_score                    | RF1             | 0.00684231045187707      |\n",
            "| tau_match_score                | RF1             | 0.308694618272841        |\n",
            "| tau_iptw_score                 | RF1             | 1.1122600840814265       |\n",
            "| tau_iptw_clip_prop_score       | RF1             | 1.1122600840814265       |\n",
            "| tau_dr_score                   | RF1             | 0.7807718882678049       |\n",
            "| tau_dr_clip_prop_score         | RF1             | 0.7807718882678049       |\n",
            "| influence_score                | RF1             | -0.00020662931602441178  |\n",
            "| influence_clip_prop_score      | RF1             | -0.00020662931602441178  |\n",
            "| r_score                        | RF1             | 0.12001805782836973      |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare All Estimators\n",
        "\n",
        "Run the following code to run the evaluation code on all the estimators and output a table.\n",
        "\n"
      ],
      "metadata": {
        "id": "M16jyHCulFdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator_set = [\"OLS1\", \"OLS2\", \"NN1\", \"NN2\", \"RF1\", \"RF2\", \"Dragonnet\", \"TARNet\"]\n",
        "overall_res_in = {}\n",
        "overall_res_out = {}\n",
        "for estimator in estimator_set:\n",
        "  res_in, res_out = evaluate(estimator, metric_set, False)\n",
        "  for metric in metric_set:\n",
        "    res_in[estimator][metric] = str(res_in[estimator][metric][\"mean\"])\n",
        "    res_out[estimator][metric] = str(res_out[estimator][metric][\"mean\"])\n",
        "  overall_res_in.update(res_in)\n",
        "  overall_res_out.update(res_out)"
      ],
      "metadata": {
        "id": "Yr9LLRoCleTh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "def print_dict_as_table(dictionary):\n",
        "    headers = ['Metric'] + list(dictionary.keys())\n",
        "    rows = []\n",
        "    inner_keys = list(dictionary[headers[1]].keys())\n",
        "\n",
        "    for key in inner_keys:\n",
        "        row = [key] + [dictionary[header][key] for header in headers[1:]]\n",
        "        rows.append(row)\n",
        "\n",
        "    print(tabulate(rows, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "print(\"In-Sample\")\n",
        "print_dict_as_table(overall_res_in)\n",
        "print(\"Out-of-Sample\")\n",
        "print_dict_as_table(overall_res_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek8y9cAysmfU",
        "outputId": "b67939b5-f1c8-4d93-f3fb-66314197606d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-Sample\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| Metric                    |        OLS1 |        OLS2 |        NN1 |         NN2 |         RF1 |         RF2 |   Dragonnet |       TARNet |\n",
            "+===========================+=============+=============+============+=============+=============+=============+=============+==============+\n",
            "| MAE                       |  0.0623437  |  0.0570956  |  0.0498738 |  0.0293713  |  0.0508981  |   0.0666528 |   0.142501  |  0.0472613   |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| PEHE                      |  0.328746   |  0.33747    |  0.355407  |  0.440053   |  0.307971   |   0.324633  |   0.397949  |  0.351776    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| value_score               |  0.159638   |  0.159403   |  0.126034  |  0.0568956  |  0.00919589 | nan         |   0.133398  |  0.108931    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| value_dr_score            | -0.0800128  | -0.0837894  | -0.114344  | -0.189577   | -0.296973   |  -0.31183   |  -0.104741  | -0.131684    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| value_dr_clip_prop_score  | -0.0800128  | -0.0837894  | -0.114344  | -0.189577   | -0.296973   |  -0.31183   |  -0.104741  | -0.131684    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_t_score               |  0.00565492 |  0.00857015 |  0.0296574 |  0.143261   |  0.0271347  |   0.0607047 |   0.0558308 |  0.0234387   |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_s_score               |  0.00105428 |  0.00763577 |  0.0281239 |  0.145192   |  0.0256111  |   0.0612888 |   0.0561673 |  0.0239344   |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_match_score           |  0.30851    |  0.312004   |  0.307404  |  0.287287   |  0.237416   |   0.198628  |   0.318427  |  0.303851    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_iptw_score            |  1.19734    |  1.18866    |  1.11924   |  0.989165   |  1.01348    |   0.894461  |   1.11628   |  1.16706     |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_iptw_clip_prop_score  |  1.19734    |  1.18866    |  1.11924   |  0.989165   |  1.01348    |   0.894461  |   1.11628   |  1.16706     |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_dr_score              |  0.817897   |  0.811586   |  0.747456  |  0.626197   |  0.630831   |   0.519958  |   0.761391  |  0.788101    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| tau_dr_clip_prop_score    |  0.817897   |  0.811586   |  0.747456  |  0.626197   |  0.630831   |   0.519958  |   0.761391  |  0.788101    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| influence_score           | -8.4954e-05 |  0.00650017 |  0.0240367 | -0.00983062 | -0.0548432  |  -0.0841777 |   0.0833135 |  0.000290856 |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| influence_clip_prop_score | -8.4954e-05 |  0.00650017 |  0.0240367 | -0.00983062 | -0.0548432  |  -0.0841777 |   0.0833135 |  0.000290856 |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "| r_score                   |  0.125494   |  0.124169   |  0.112476  |  0.0893019  |  0.0920457  |   0.0707536 |   0.116268  |  0.119548    |\n",
            "+---------------------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+--------------+\n",
            "Out-of-Sample\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| Metric                    |        OLS1 |        OLS2 |        NN1 |        NN2 |          RF1 |        RF2 |   Dragonnet |     TARNet |\n",
            "+===========================+=============+=============+============+============+==============+============+=============+============+\n",
            "| MAE                       |  0.0630765  |  0.0560392  |  0.052116  |  0.0319728 |  0.0463579   |  0.0600626 |   0.140727  |  0.0454881 |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| PEHE                      |  0.314498   |  0.326353   |  0.357055  |  0.481782  |  0.325384    |  0.334487  |   0.398374  |  0.345686  |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| value_score               |  0.140937   |  0.156054   |  0.168073  |  0.171538  |  0.188853    |  0.166888  |   0.145004  |  0.163462  |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| value_dr_score            | -0.0831077  | -0.0704452  | -0.0671577 | -0.0583301 | -0.0482009   | -0.0655945 |  -0.0823647 | -0.0677715 |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| value_dr_clip_prop_score  | -0.0831077  | -0.0704452  | -0.0671577 | -0.0583301 | -0.0482009   | -0.0655945 |  -0.0823647 | -0.0677715 |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_t_score               |  0.00534111 |  0.00860464 |  0.0288204 |  0.126273  |  0.00873143  |  0.0125878 |   0.056087  |  0.0238421 |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_s_score               |  0.00106698 |  0.00788482 |  0.0272594 |  0.127878  |  0.00684231  |  0.0124    |   0.0566822 |  0.0249136 |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_match_score           |  0.297737   |  0.307024   |  0.322053  |  0.430436  |  0.308695    |  0.308427  |   0.340685  |  0.319223  |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_iptw_score            |  1.09992    |  1.10531    |  1.13535   |  1.2276    |  1.11226     |  1.11037   |   1.13731   |  1.12043   |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_iptw_clip_prop_score  |  1.09992    |  1.10531    |  1.13535   |  1.2276    |  1.11226     |  1.11037   |   1.13731   |  1.12043   |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_dr_score              |  0.770602   |  0.776594   |  0.797755  |  0.896174  |  0.780772    |  0.780978  |   0.815605  |  0.78775   |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| tau_dr_clip_prop_score    |  0.770602   |  0.776594   |  0.797755  |  0.896174  |  0.780772    |  0.780978  |   0.815605  |  0.78775   |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| influence_score           | -0.00062029 |  0.0105145  |  0.0262051 |  0.117142  | -0.000206629 |  0.0105297 |   0.0965012 |  0.01716   |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| influence_clip_prop_score | -0.00062029 |  0.0105145  |  0.0262051 |  0.117142  | -0.000206629 |  0.0105297 |   0.0965012 |  0.01716   |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n",
            "| r_score                   |  0.117876   |  0.11917    |  0.123144  |  0.141133  |  0.120018    |  0.120112  |   0.127222  |  0.121297  |\n",
            "+---------------------------+-------------+-------------+------------+------------+--------------+------------+-------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] J. L. Hill, “Bayesian nonparametric modeling for causal inference,” Journal\n",
        "of Computational  and Graphical Statistics, vol. 20, no. 1, pp. 217–240, 2011.\n",
        "[Online]. Available: https://doi.org/10.1198/jcgs.2010.08162\n",
        "\n",
        "[2] R. J. LaLonde, “Evaluating the econometric evaluations of training programs\n",
        "with experimental data,” The American Economic Review, vol. 76, no. 4, pp.\n",
        "604–620, 1986. [Online]. Available: http://www.jstor.org/stable/1806062\n",
        "\n",
        "[3] U. Shalit, F. D. Johansson, and D. Sontag, “Estimating individual treatment\n",
        "effect: generalization bounds and algorithms,” in Proceedings of the 34th\n",
        "International Conference on Machine Learning, ser. Proceedings of Machine\n",
        "Learning Research, D. Precup and Y. W. Teh, Eds., vol. 70. PMLR, 06–11 Aug 2017\n",
        ", pp. 3076–3085. [Online].\n",
        "Available: https://proceedings.mlr.press/v70/shalit17a.html\n",
        "\n",
        "[4] Christos Louizos, Uri Shalit, Joris Mooij, David Sontag, Richard Zemel, and Max Welling. Causal effect inference with deep latent-variable models. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS'17), 6449–6459, 2017.\n",
        "\n",
        "[5] D. Almond, K. Y. Chay, and D. S. Lee. The costs of low birth weight.The Quarterly Journal of Economics,120(3):1031–1083, 2005.\n",
        "\n",
        "[6] D. Mahajan, I. Mitliagkas, B. Neal, and V. Syrgkanis, ‘Empirical Analysis of Model Selection for Heterogenous Causal Effect Estimation’, arXiv [cs.LG]. 2022.\n"
      ],
      "metadata": {
        "id": "6LqqReqIlQZg"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a0b5a31022a61b32d9bd73ec997b0a079a20f27350e8c7766473b50790ea745"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}